use std::fs::{self, File};
use std::io::Cursor;
use std::path::{Path, PathBuf};

use anyhow::{anyhow, Context, Result};
use base64::{engine::general_purpose, Engine as _};
use clap::{Parser, Subcommand};
use image::codecs::ico::IcoEncoder;
use image::codecs::png::PngEncoder;
use image::imageops::{resize, FilterType};
use image::{ColorType, DynamicImage, GenericImage, ImageBuffer, Rgba, RgbaImage};
use image::ImageEncoder;
use reqwest::Client;
use serde::{Deserialize, Serialize};
use serde_json::Value;
use tauri_app_lib::{config, logging};
use tracing::{error, info};

const IMAGE_MODEL: &str = "gemini-3-pro-image-preview";
const IMAGE_PROMPT_STYLE: &str = "Create a minimalist, modern horizontal wordmark logo (4:1 aspect) with an icon on the left and clear text on the right. Use dark tones, clean typography, and avoid photorealism. The background should be bright lime green (#00FF00) to act as a greenscreen, but keep the logo colors distinct and readable.";
const ICON_EXTRACTION_PROMPT: &str = "Remove ALL TEXT from this image. Keep ONLY the icon/symbol from the left side, center it in a square 1:1 aspect ratio, and preserve the BRIGHT LIME GREEN (#00FF00) background exactly as it appears. Do not tweak the icon colors, just remove the text and center the symbol.";
const BANNER_STYLE_PROMPT: &str = "Style the image in a Japanese minimalist sumi-e ink wash style with monochrome tones, fluid brushstrokes, and thoughtful negative space. Use a wide 16:9 composition, keep the view horizontal, and make the banner the dominant focal point with legible text centered at the top.";

#[derive(Parser)]
#[command(author, version, about = "Legacy asset generator replacement", long_about = None)]
struct Cli {
    #[command(subcommand)]
    command: Command,
}

#[derive(Subcommand)]
enum Command {
    /// Generate the project logo, icons, and favicon
    Logo {
        /// Project name used in prompts
        #[arg(long)]
        project_name: Option<String>,
        /// Optional creative suggestion for the wordmark
        #[arg(long)]
        suggestion: Option<String>,
        /// Where to write assets (defaults to docs/public)
        #[arg(long)]
        output_dir: Option<PathBuf>,
    },
    /// Generate the hero banner image
    Banner {
        /// Title/text that belongs on the banner
        #[arg(long)]
        title: Option<String>,
        /// Optional guiding suggestion for the description
        #[arg(long)]
        suggestion: Option<String>,
        /// Output directory for the banner (defaults to media/)
        #[arg(long)]
        output_dir: Option<PathBuf>,
    },
}

#[tokio::main]
async fn main() -> Result<()> {
    logging::init_logging();
    let cli = Cli::parse();
    let client = GeminiClient::new()?;

    match cli.command {
        Command::Logo {
            project_name,
            suggestion,
            output_dir,
        } => run_logo(project_name, suggestion, output_dir, client).await,
        Command::Banner {
            title,
            suggestion,
            output_dir,
        } => run_banner(title, suggestion, output_dir, client).await,
    }
}

async fn run_logo(
    project_name: Option<String>,
    suggestion: Option<String>,
    output_dir: Option<PathBuf>,
    client: GeminiClient,
) -> Result<()> {
    let workspace = workspace_root()?;
    let project_name = project_name.unwrap_or_else(|| {
        read_project_name(&workspace).unwrap_or_else(|_| "Tauri-Template".into())
    });
    let target = output_dir.unwrap_or_else(|| workspace.join("docs").join("public"));
    fs::create_dir_all(&target).context("Failed to create output directory")?;

    info!("Generating wordmark for {}...", project_name);
    let description = client
        .generate_text_description(&project_name, suggestion.as_deref())
        .await
        .context("Failed to describe the wordmark")?;

    let prompt = format!(
        "{description}. Create a HORIZONTAL 4:1 wordmark logo (3200x800) that includes the text '{project_name}'. {IMAGE_PROMPT_STYLE} Use DARK colors to match a light mode header, keep the icon on the left, and ensure the lime-green background exists only to support chroma-keying.",
    );

    let mut light_image = client
        .generate_image(IMAGE_MODEL, &prompt)
        .await
        .context("Failed to generate light mode wordmark")?
        .to_rgba8();
    let icon_reference = light_image.clone();
    info!("Extracting icon from wordmark...");
    let icon_prompt = format!(
        "{ICON_EXTRACTION_PROMPT} Remove the text '{project_name}' and keep only the icon."
    );
    let mut icon_light = client
        .generate_image_from_reference(IMAGE_MODEL, &icon_prompt, &icon_reference)
        .await
        .context("Failed to extract icon")?
        .to_rgba8();

    remove_greenscreen(&mut light_image, 60);
    save_png(&light_image, &target.join("logo-light.png"))?;
    info!(
        "Saved light wordmark at {}",
        target.join("logo-light.png").display()
    );
    remove_greenscreen(&mut icon_light, 60);

    let mut dark_wordmark = light_image.clone();
    invert_colors(&mut dark_wordmark);
    save_png(&dark_wordmark, &target.join("logo-dark.png"))?;
    info!(
        "Saved dark wordmark at {}",
        target.join("logo-dark.png").display()
    );

    let mut icon_dark = icon_light.clone();
    invert_colors(&mut icon_dark);

    let icon_light_square = ensure_square(&icon_light);
    let icon_dark_square = ensure_square(&icon_dark);

    let icon_light_512 = resize(&icon_light_square, 512, 512, FilterType::Lanczos3);
    let icon_dark_512 = resize(&icon_dark_square, 512, 512, FilterType::Lanczos3);
    let favicon_32 = resize(&icon_light_square, 32, 32, FilterType::Lanczos3);

    save_png(&icon_light_512, &target.join("icon-light.png"))?;
    save_png(&icon_dark_512, &target.join("icon-dark.png"))?;
    save_ico(&favicon_32, &target.join("favicon.ico"))?;

    info!("Logo assets saved to {}", target.display());
    Ok(())
}

async fn run_banner(
    title: Option<String>,
    suggestion: Option<String>,
    output_dir: Option<PathBuf>,
    client: GeminiClient,
) -> Result<()> {
    let workspace = workspace_root()?;
    let title = title.unwrap_or_else(|| {
        read_project_name(&workspace).unwrap_or_else(|_| "Tauri-Template".into())
    });
    let target = output_dir.unwrap_or_else(|| workspace.join("media"));
    fs::create_dir_all(&target).context("Failed to create banner output directory")?;

    let banner_description = client
        .generate_banner_description(&title, suggestion.as_deref())
        .await
        .context("Failed to describe banner")?;

    let full_prompt = format!(
        "{banner_description}. Create a WIDE 16:9 horizontal image where the banner takes up 80% of the screen and the text '{title}' is centered at the top with excellent contrast. {BANNER_STYLE_PROMPT}",
    );

    let banner = client
        .generate_image(IMAGE_MODEL, &full_prompt)
        .await
        .context("Failed to generate banner")?;
    let banner_path = target.join("banner.png");
    banner
        .save(&banner_path)
        .context("Failed to write banner image")?;

    info!("Banner saved to {}", banner_path.display());
    Ok(())
}

fn save_png(image: &RgbaImage, path: &Path) -> Result<()> {
    image
        .save(path)
        .with_context(|| format!("Failed to save PNG at {}", path.display()))
}

fn save_ico(image: &RgbaImage, path: &Path) -> Result<()> {
    let file = File::create(path)
        .with_context(|| format!("Failed to open ICO file at {}", path.display()))?;
    let encoder = IcoEncoder::new(file);
    encoder
        .write_image(
            image.as_raw(),
            image.width(),
            image.height(),
            ColorType::Rgba8.into(),
        )
        .with_context(|| format!("Failed to write ICO at {}", path.display()))
}

fn remove_greenscreen(image: &mut RgbaImage, tolerance: i32) {
    for pixel in image.pixels_mut() {
        let [r, mut g, b, mut a] = pixel.0;
        let tolerance_f = tolerance as f32;
        let r_f = r as f32;
        let g_f = g as f32;
        let b_f = b as f32;

        let green_high = g_f > 180.0;
        let green_dominant =
            g_f > r_f + tolerance_f + 20.0 && g_f > b_f + tolerance_f + 20.0;
        if green_high && green_dominant {
            a = 0;
        }

        let visible = a > 128;
        let has_green_tint = g_f > r_f + 20.0 && g_f > b_f + 20.0;
        if visible && has_green_tint {
            let avg_rb = (r_f + b_f) / 2.0;
            let new_g = (g_f * 0.6).min(avg_rb);
            g = new_g.clamp(0.0, 255.0) as u8;
        }

        pixel.0 = [r, g, b, a];
    }
}

fn invert_colors(image: &mut RgbaImage) {
    for pixel in image.pixels_mut() {
        let [r, g, b, a] = pixel.0;
        pixel.0 = [255 - r, 255 - g, 255 - b, a];
    }
}

fn ensure_square(image: &RgbaImage) -> RgbaImage {
    let size = image.width().max(image.height());
    let mut square = ImageBuffer::from_pixel(size, size, Rgba([255, 255, 255, 0]));
    let offset_x = (size - image.width()) / 2;
    let offset_y = (size - image.height()) / 2;
    square
        .copy_from(image, offset_x, offset_y)
        .expect("Failed to center image in square canvas");
    square
}

fn workspace_root() -> Result<PathBuf> {
    let manifest_dir = env!("CARGO_MANIFEST_DIR");
    Path::new(manifest_dir)
        .parent()
        .map(Path::to_path_buf)
        .ok_or_else(|| anyhow!("Unable to determine workspace root"))
}

fn read_project_name(workspace: &Path) -> Result<String> {
    let package_json = workspace.join("package.json");
    let data = fs::read_to_string(&package_json)
        .with_context(|| format!("Failed to read {}", package_json.display()))?;
    let json: Value = serde_json::from_str(&data).context("Invalid package.json")?;
    json.get("name")
        .and_then(|value| value.as_str())
        .map(|s| s.to_string())
        .ok_or_else(|| anyhow!("package.json does not declare a name"))
}

struct GeminiClient {
    http: Client,
    api_key: String,
    text_model: String,
}

impl GeminiClient {
    fn new() -> Result<Self> {
        let cfg = config::get_config();
        let api_key = cfg
            .gemini_api_key()
            .ok_or_else(|| anyhow!("Missing APP__GEMINI_API_KEY"))?
            .to_string();
        let text_model = cfg.model_name.clone();
        Ok(Self {
            http: Client::new(),
            api_key,
            text_model,
        })
    }

    async fn generate_text_description(
        &self,
        title: &str,
        suggestion: Option<&str>,
    ) -> Result<String> {
        let prompt = format!(
            "Create a concise, creative description of a modern horizontal wordmark for '{title}'. {}",
            suggestion.unwrap_or(""),
        );
        self.generate_text(&self.text_model, &prompt).await
    }

    async fn generate_banner_description(
        &self,
        title: &str,
        suggestion: Option<&str>,
    ) -> Result<String> {
        let prompt = format!(
            "Describe a Japanese-style banner featuring the text '{title}'. {}",
            suggestion.unwrap_or(""),
        );
        self.generate_text(&self.text_model, &prompt).await
    }

    async fn generate_text(&self, model: &str, prompt: &str) -> Result<String> {
        let request = GenerateContentRequest::new_text(prompt);
        let response = self.send_request(model, &request).await?;
        extract_text(&response).ok_or_else(|| anyhow!("No text returned from Gemini"))
    }

    async fn generate_image(&self, model: &str, prompt: &str) -> Result<DynamicImage> {
        let request = GenerateContentRequest::new_image(prompt);
        let response = self.send_request(model, &request).await?;
        extract_first_image(&response).ok_or_else(|| anyhow!("No image returned from Gemini"))
    }

    async fn generate_image_from_reference(
        &self,
        model: &str,
        prompt: &str,
        reference: &RgbaImage,
    ) -> Result<DynamicImage> {
        let inline = inline_image_from_rgba(reference)?;
        let request = GenerateContentRequest::new_image_with_ref(prompt, inline);
        let response = self.send_request(model, &request).await?;
        extract_first_image(&response)
            .ok_or_else(|| anyhow!("No inline image returned from Gemini"))
    }

    async fn send_request(
        &self,
        model: &str,
        payload: &GenerateContentRequest,
    ) -> Result<GenerateContentResponse> {
        let url = format!(
            "https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent"
        );
        let response = self
            .http
            .post(&url)
            .bearer_auth(&self.api_key)
            .json(payload)
            .send()
            .await
            .context("Failed to reach Gemini API")?;

        let status = response.status();
        if !status.is_success() {
            let body: String = response.text().await.unwrap_or_default();
            error!("Gemini returned {}: {}", status, body);
            return Err(anyhow!("Gemini request failed"));
        }

        response
            .json::<GenerateContentResponse>()
            .await
            .context("Failed to decode Gemini response")
    }
}

fn inline_image_from_rgba(image: &RgbaImage) -> Result<InlineImage> {
    let mut buffer = Vec::new();
    PngEncoder::new(Cursor::new(&mut buffer))
        .write_image(
            image.as_raw(),
            image.width(),
            image.height(),
            ColorType::Rgba8.into(),
        )
        .context("Failed to encode reference image")?;
    Ok(InlineImage {
        mime_type: "image/png".into(),
        data: general_purpose::STANDARD.encode(&buffer),
    })
}

fn extract_text(response: &GenerateContentResponse) -> Option<String> {
    response
        .candidates
        .iter()
        .flat_map(|candidate| candidate.content.parts.iter())
        .filter_map(|part| part.text.clone())
        .next()
}

fn extract_first_image(response: &GenerateContentResponse) -> Option<DynamicImage> {
    for candidate in &response.candidates {
        for part in &candidate.content.parts {
            if let Some(data) = &part.inline_data {
                if data.mime_type.starts_with("image/") {
                    if let Ok(bytes) = general_purpose::STANDARD.decode(&data.data) {
                        if let Ok(img) = image::load_from_memory(&bytes) {
                            return Some(img);
                        }
                    }
                }
            }
        }
    }
    None
}

#[derive(Serialize)]
struct GenerateContentRequest {
    response_modalities: Vec<String>,
    contents: Vec<ContentInput>,
    config: GenerateContentConfig,
}

impl GenerateContentRequest {
    fn new_text(prompt: &str) -> Self {
        Self {
            response_modalities: vec!["TEXT".into()],
            contents: vec![ContentInput::Text(TextContent {
                text: prompt.into(),
            })],
            config: GenerateContentConfig {
                response_modalities: vec!["TEXT".into()],
            },
        }
    }

    fn new_image(prompt: &str) -> Self {
        Self {
            response_modalities: vec!["IMAGE".into(), "TEXT".into()],
            contents: vec![ContentInput::Text(TextContent {
                text: prompt.into(),
            })],
            config: GenerateContentConfig {
                response_modalities: vec!["IMAGE".into(), "TEXT".into()],
            },
        }
    }

    fn new_image_with_ref(prompt: &str, inline: InlineImage) -> Self {
        Self {
            response_modalities: vec!["IMAGE".into(), "TEXT".into()],
            contents: vec![
                ContentInput::Text(TextContent {
                    text: prompt.into(),
                }),
                ContentInput::Image(ImageContent { image: inline }),
            ],
            config: GenerateContentConfig {
                response_modalities: vec!["IMAGE".into(), "TEXT".into()],
            },
        }
    }
}

#[derive(Serialize)]
struct GenerateContentConfig {
    response_modalities: Vec<String>,
}

#[derive(Serialize)]
#[serde(untagged)]
enum ContentInput {
    Text(TextContent),
    Image(ImageContent),
}

#[derive(Serialize)]
struct TextContent {
    text: String,
}

#[derive(Serialize)]
struct ImageContent {
    image: InlineImage,
}

#[derive(Serialize)]
struct InlineImage {
    mime_type: String,
    data: String,
}

#[derive(Deserialize)]
struct GenerateContentResponse {
    candidates: Vec<Candidate>,
}

#[derive(Deserialize)]
struct Candidate {
    content: Content,
}

#[derive(Deserialize)]
struct Content {
    parts: Vec<ContentPart>,
}

#[derive(Deserialize)]
struct ContentPart {
    text: Option<String>,
    inline_data: Option<InlineData>,
}

#[derive(Deserialize)]
struct InlineData {
    mime_type: String,
    data: String,
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn remove_greenscreen_hides_green_pixel() {
        let mut image = ImageBuffer::from_pixel(1, 1, Rgba([0, 255, 0, 255]));
        remove_greenscreen(&mut image, 60);
        assert_eq!(image.get_pixel(0, 0)[3], 0);
    }

    #[test]
    fn invert_colors_flips_rgb_only() {
        let mut image = ImageBuffer::from_pixel(1, 1, Rgba([10, 20, 30, 200]));
        invert_colors(&mut image);
        assert_eq!(image.get_pixel(0, 0), &Rgba([245, 235, 225, 200]));
    }

    #[test]
    fn ensure_square_adds_padding() {
        let image = ImageBuffer::from_pixel(10, 20, Rgba([1, 2, 3, 4]));
        let square = ensure_square(&image);
        assert_eq!(square.width(), square.height());
        assert!(square.width() >= image.height());
    }
}
